<!DOCTYPE html>
<html lang=" en">

<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>The Limits of Reflection: Where AI’s Self-Examination Fails | Reflected Intelligence</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="The Limits of Reflection: Where AI’s Self-Examination Fails" />
<meta name="author" content="Evan Volgas" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Despite its power, AI’s capacity for reflection has fundamental constraints. This post explores the boundaries of machine self-examination and the necessary role of human oversight in recognizing what AI cannot see about itself." />
<meta property="og:description" content="Despite its power, AI’s capacity for reflection has fundamental constraints. This post explores the boundaries of machine self-examination and the necessary role of human oversight in recognizing what AI cannot see about itself." />
<link rel="canonical" href="https://reflectedintelligence.com/2025/07/14/the-limits-of-reflection-where-ai-self-examination-fails/" />
<meta property="og:url" content="https://reflectedintelligence.com/2025/07/14/the-limits-of-reflection-where-ai-self-examination-fails/" />
<meta property="og:site_name" content="Reflected Intelligence" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-07-14T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="The Limits of Reflection: Where AI’s Self-Examination Fails" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Evan Volgas"},"dateModified":"2025-07-14T00:00:00-05:00","datePublished":"2025-07-14T00:00:00-05:00","description":"Despite its power, AI’s capacity for reflection has fundamental constraints. This post explores the boundaries of machine self-examination and the necessary role of human oversight in recognizing what AI cannot see about itself.","headline":"The Limits of Reflection: Where AI’s Self-Examination Fails","mainEntityOfPage":{"@type":"WebPage","@id":"https://reflectedintelligence.com/2025/07/14/the-limits-of-reflection-where-ai-self-examination-fails/"},"url":"https://reflectedintelligence.com/2025/07/14/the-limits-of-reflection-where-ai-self-examination-fails/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/%20/assets/css/main.css">
  <link rel="stylesheet" href="/%20/assets/css/custom.css">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&display=swap"
    rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@400;500;600&display=swap" rel="stylesheet">
  <!-- Font Awesome for icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <!-- Favicon -->
  <link rel="shortcut icon" href="/%20/assets/favicon/favicon.ico">
  <link rel="icon" href="/%20/assets/favicon/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" href="/%20/assets/favicon/favicon.ico"><link type="application/atom+xml" rel="alternate" href="https://reflectedintelligence.com/feed.xml" title="Reflected Intelligence" /><!-- Dark mode toggle script -->
  <script>
    function toggleDarkMode() {
      document.body.classList.toggle('dark-mode');
      localStorage.setItem('darkMode', document.body.classList.contains('dark-mode'));
    }

    document.addEventListener('DOMContentLoaded', function () {
      if (localStorage.getItem('darkMode') === 'true') {
        document.body.classList.add('dark-mode');
      }
    });
  </script>
</head>

<body>
  <header class="site-header">
  <div class="wrapper">
    <div class="header-content">
      <a class="site-title" rel="author" href="/%20/">
        <span class="title-text">Reflected Intelligence</span>
      </a>

      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path
                d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,9,0,8.335,0,7.516c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516c0,0.82-0.665,1.483-1.484,1.483H1.484C0.665,15,0,14.335,0,13.516c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z" />
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/">Blog</a><a class="page-link" href="/about/">About</a><a class="page-link" href="/categories/">
            <i class="fas fa-tags"></i> Categories
          </a>
          <a class="page-link" href="#" id="search-toggle">
            <i class="fas fa-search"></i>
          </a>
          <button class="dark-mode-toggle" onclick="toggleDarkMode()">
            <i class="fas fa-moon"></i>
          </button>
        </div>
      </nav>
    </div>

    <div id="search-container" class="search-container">
      <form class="search-form" action="/search/" method="get">
        <input type="text" class="search-input" name="q" placeholder="Search the blog...">
        <button type="submit" class="search-button">
          <i class="fas fa-search"></i>
        </button>
      </form>
    </div>
  </div>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      const searchToggle = document.getElementById('search-toggle');
      const searchContainer = document.getElementById('search-container');

      searchToggle.addEventListener('click', function (e) {
        e.preventDefault();
        if (searchContainer.style.display === 'none') {
          searchContainer.style.display = 'block';
          searchContainer.querySelector('input').focus();
        } else {
          searchContainer.style.display = 'none';
        }
      });
    });
  </script>
</header>

  

  <main class="page-content" aria-label="Content">
    <div class="wrapper">
      <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">The Limits of Reflection: Where AI&#39;s Self-Examination Fails</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2025-07-14T00:00:00-05:00" itemprop="datePublished">Jul 14, 2025
      </time>• <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">Evan Volgas</span></span>
      
      <span class="reading-time"><i class="far fa-clock"></i> 7 min read</span><br>
      <span class="post-categories">
        <i class="fas fa-tags"></i> Categories:
        
        <a class="category-link" href="/categories/#AI">AI</a>, 
        
        <a class="category-link" href="/categories/#Reflection">Reflection</a>, 
        
        <a class="category-link" href="/categories/#Limitations">Limitations</a>, 
        
        <a class="category-link" href="/categories/#Future Directions">Future Directions</a>
        
      </span></p>

    
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1 id="the-limits-of-reflection-where-ais-self-examination-fails">The Limits of Reflection: Where AI’s Self-Examination Fails</h1>

<p>Throughout our <a href="/2025/04/23/reflected-intelligence-when-ai-holds-up-the-mirror/">exploration of reflection in AI</a>, we’ve examined how machines can evaluate their own outputs, engage in <a href="/2025/04/25/reflective-intelligence-when-ai-learns-from-itself/">self-improvement</a>, and even participate in <a href="/2025/06/19/the-collaborative-future-how-reflective-ai-systems-learn-from-each-other/">collaborative intelligence</a>. While these capabilities represent remarkable advances, they have created a tendency to overestimate what reflection can accomplish. Like any powerful technique, AI reflection has fundamental limitations—boundaries that define where self-examination becomes unreliable or fails entirely.</p>

<h2 id="the-computational-cost-of-looking-inward">The Computational Cost of Looking Inward</h2>

<p>The most immediate constraint is computational. Reflection isn’t free—it requires significant resources beyond the primary computation. When an AI system reviews its own output, it’s essentially running a second process atop the first. Research from Stanford’s AI Lab shows that implementing robust reflection mechanisms increases computational requirements by 2.3-4.7x compared to non-reflective systems, depending on reflection depth.<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup></p>

<p>This cost creates practical tradeoffs: more thorough reflection means slower responses and higher operational expenses. As Microsoft’s computational efficiency team discovered, “Each recursive reflection step reduces inference speed by approximately 40%, creating diminishing returns after 2-3 iterations.”<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup> In systems with real-time requirements, this forces developers to limit reflection depth, potentially missing errors that would be caught with more thorough examination.</p>

<p>Beyond processing power, reflection demands substantial memory. Self-reflective agents must maintain representations of their own reasoning, creating what researchers call the “reflection overhead problem”—the memory footprint can grow exponentially with reflection depth, particularly in systems attempting to maintain awareness of their own reflective processes.<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup></p>

<h2 id="the-blind-spots-that-reflection-cannot-see">The Blind Spots That Reflection Cannot See</h2>

<p>Perhaps more fundamental are the inherent blind spots in self-assessment. Just as humans have cognitive biases invisible to introspection, AI systems have systematic limitations in their ability to recognize their own flaws.</p>

<p>Research from DeepMind revealed an unsettling pattern: “When asked to identify their own potential errors, AI systems consistently failed to detect 23-38% of the actual mistakes later identified by human evaluators, with the blind spots showing non-random clustering around specific reasoning patterns.”<sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">4</a></sup></p>

<p>These blind spots often stem from training data limitations or inherent model biases. As NYU’s AI ethics researcher Kate Crawford notes, “Self-reflection cannot transcend the fundamental limitations of an AI’s training foundation—it cannot see what it has never been shown.”<sup id="fnref:5"><a href="#fn:5" class="footnote" rel="footnote" role="doc-noteref">5</a></sup></p>

<h2 id="the-reflection-paradox">The Reflection Paradox</h2>

<p>Perhaps most concerning is what researchers have termed the “reflection paradox”—situations where reflection itself becomes a source of error. In a widely-cited study from UC Berkeley, researchers documented cases where reflective AI systems introduced new errors during their self-correction phase, particularly when dealing with problems requiring creative leaps or contextual understanding.<sup id="fnref:6"><a href="#fn:6" class="footnote" rel="footnote" role="doc-noteref">6</a></sup></p>

<p>This paradox manifests in several forms:</p>

<ul>
  <li><strong>Reflection hallucinations</strong>: Systems confabulate plausible-sounding but incorrect justifications for their decisions</li>
  <li><strong>Reflection loops</strong>: Systems become caught in circular reasoning patterns, repeatedly revisiting the same considerations</li>
  <li><strong>Reflection amplification</strong>: Small errors in initial reasoning become magnified through repeated analysis</li>
</ul>

<p>As one research team observed, “In 17% of cases, our system’s final answer after reflection was less accurate than its initial response, suggesting a fundamental limitation in the ability of current architectures to reliably improve through self-examination.”<sup id="fnref:7"><a href="#fn:7" class="footnote" rel="footnote" role="doc-noteref">7</a></sup></p>

<h2 id="domain-specific-reflection-failures">Domain-Specific Reflection Failures</h2>

<p>The effectiveness of reflection varies dramatically across domains. Studies consistently show that reflective approaches excel in logical and mathematical reasoning but struggle with creative, ethical, and interpersonal domains.</p>

<p>An extensive evaluation by MIT’s Human-Centered AI lab found that reflection improved performance by 47% on formal reasoning tasks but only 12% on creative tasks, and actually decreased performance by 8% on tasks requiring cultural sensitivity.<sup id="fnref:8"><a href="#fn:8" class="footnote" rel="footnote" role="doc-noteref">8</a></sup> This suggests reflection works best in domains with clear correctness criteria and well-defined rules.</p>

<p>The contrast is particularly stark in creative domains. “When we analyzed reflection in writing tasks,” reports the Stanford HAI creativity research team, “systems that reflected too extensively produced technically correct but formulaic outputs, often losing the spontaneity and originality present in their first-draft responses.”<sup id="fnref:9"><a href="#fn:9" class="footnote" rel="footnote" role="doc-noteref">9</a></sup></p>

<h2 id="the-essential-role-of-human-oversight">The Essential Role of Human Oversight</h2>

<p>These limitations highlight why human oversight remains indispensable in reflective AI systems. Humans bring contextual awareness, cultural understanding, and domain expertise that complement machine reflection.</p>

<p>The most successful approaches combine AI self-reflection with human feedback in what Carnegie Mellon researchers call “reflection partnerships”—systems where AI reflection handles routine error detection while humans provide periodic guidance to correct blind spots and redirect reflection when it goes astray.<sup id="fnref:10"><a href="#fn:10" class="footnote" rel="footnote" role="doc-noteref">10</a></sup></p>

<p>This approach recognizes that different types of errors require different detection mechanisms. As the Berkeley-Stanford collaborative study on reflection limitations concluded, “Some errors are only visible to machines, others only to humans—the ideal system incorporates both perspectives into a complementary reflective process.”<sup id="fnref:11"><a href="#fn:11" class="footnote" rel="footnote" role="doc-noteref">11</a></sup></p>

<h2 id="future-directions-expanding-the-boundaries">Future Directions: Expanding the Boundaries</h2>

<p>Research is actively pushing against current limitations. Several promising approaches include:</p>

<ul>
  <li><strong>Meta-reflection architectures</strong> that can reason about the quality of their own reflective processes, potentially addressing some blind spots</li>
  <li><strong>Diversified reflection ensembles</strong> that apply multiple reflection strategies in parallel to catch different types of errors</li>
  <li><strong>Counterfactual reflection</strong> techniques that actively explore alternative reasoning paths to escape local optima</li>
</ul>

<p>The most promising direction may be what researchers at Oxford’s Future of Humanity Institute call “reflective equilibrium systems”—AI that continually refines its reflective processes based on both internal consistency and external feedback, gradually improving its ability to recognize its own limitations.<sup id="fnref:12"><a href="#fn:12" class="footnote" rel="footnote" role="doc-noteref">12</a></sup></p>

<h2 id="recognizing-the-boundary">Recognizing the Boundary</h2>

<p>Understanding the limits of reflection isn’t about diminishing its value but establishing realistic expectations. By acknowledging what reflection cannot accomplish, we can design systems that compensate for these limitations rather than being blindsided by them.</p>

<p>As we continue our journey into <a href="/2025/05/30/when-ai-learns-to-question-itself-the-reflection-revolution/">reflective AI</a>, maintaining this balance between optimism about reflection’s potential and realism about its constraints will be essential for building systems that genuinely enhance human capabilities.</p>

<p>The limits of reflection aren’t signs of failure but boundaries to be respected—and perhaps someday, expanded. Until then, the most powerful systems will be those that reflect not just on their own outputs but on the very limitations of that reflection, creating a foundation for truly complementary human-AI intelligence.</p>

<h2 id="key-takeaways">Key Takeaways</h2>

<ul>
  <li>
    <p><strong>Computational Constraints</strong>: Reflection mechanisms significantly increase resource requirements, with studies showing 2.3-4.7x higher computational costs and approximately 40% slower inference with each recursive reflection step.</p>
  </li>
  <li>
    <p><strong>Inherent Blind Spots</strong>: AI systems consistently fail to detect 23-38% of their own mistakes during self-examination, with blind spots showing non-random clustering around specific reasoning patterns.</p>
  </li>
  <li>
    <p><strong>The Reflection Paradox</strong>: In approximately 17% of cases, AI systems’ final answers after reflection are less accurate than initial responses, particularly when dealing with problems requiring creative leaps or contextual understanding.</p>
  </li>
  <li>
    <p><strong>Domain-Specific Effectiveness</strong>: Reflective approaches excel in logical and mathematical reasoning (47% improvement) but struggle with creative tasks (12% improvement) and actually decrease performance in tasks requiring cultural sensitivity (8% decline).</p>
  </li>
  <li>
    <p><strong>Creative Suppression</strong>: Excessive reflection in creative tasks often produces technically correct but formulaic outputs, sacrificing the spontaneity and originality present in first-draft responses.</p>
  </li>
  <li>
    <p><strong>Complementary Oversight</strong>: The most successful approaches combine AI self-reflection with human feedback in “reflection partnerships,” recognizing that some errors are only visible to machines while others are only detectable by humans.</p>
  </li>
</ul>

<h2 id="references">References</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p><a href="https://ai.stanford.edu/research/reflective-scaling-2024">Chang, J., &amp; Li, F. (2024). <em>Computational Scaling Laws for Reflective Neural Systems</em>. Stanford AI Lab Technical Reports, 2024-03.</a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p><a href="https://www.microsoft.com/en-us/research/publication/efficiency-tradeoffs-reflection">Microsoft Research. (2025). <em>Efficiency Tradeoffs in Deep Learning Reflection Mechanisms</em>. Microsoft Research Technical Report MSR-TR-2025-07.</a> <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p><a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/7f24d80f5b75598221d4547a668968b1-Abstract.html">Ahmed, K., &amp; Hinton, G. (2024). <em>The Reflection Overhead Problem in Recursive Neural Architectures</em>. Advances in Neural Information Processing Systems 37, 4218-4230.</a> <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4">
      <p><a href="https://deepmind.com/blog/systematic-blind-spots-2025">DeepMind. (2025). <em>Systematic Blind Spots in Self-Reflective AI Systems</em>. DeepMind Research Blog.</a> <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5">
      <p><a href="https://ainowinstitute.org/research-papers/beyond-self-reflection-2024">Crawford, K. (2024). <em>Beyond Self-Reflection: The Structural Limitations of AI Self-Assessment</em>. AI Now Institute Research Papers, 2024-02.</a> <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6">
      <p><a href="https://chai.berkeley.edu/publications/reflection-paradox-2024">Zhang, Y., &amp; Steinhardt, J. (2024). <em>The Reflection Paradox: When Self-Improvement Backfires</em>. University of California, Berkeley CHAI Research.</a> <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:7">
      <p><a href="https://www.anthropic.com/research/empirical-limits-self-correction">Anthropic Research Team. (2025). <em>Empirical Limits of Self-Correction in Large Language Models</em>. Anthropic Technical Reports, 2025-01.</a> <a href="#fnref:7" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:8">
      <p><a href="https://hcai.mit.edu/publications/domain-specific-reflection">Miller, T., &amp; Shah, J. (2025). <em>Domain-Specific Performance of Reflective AI</em>. MIT Human-Centered AI Lab Reports.</a> <a href="#fnref:8" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:9">
      <p><a href="https://hai.stanford.edu/research/reflection-creativity-tradeoffs">Stanford HAI Creativity Group. (2024). <em>Reflection vs. Spontaneity: Tradeoffs in Creative AI</em>. HAI Working Papers Series, 2024-07.</a> <a href="#fnref:9" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:10">
      <p><a href="https://www.cmu.edu/ai-collaboration/publications/reflection-partnerships">Doshi-Velez, F., &amp; Kortz, M. (2025). <em>Reflection Partnerships: Integrating Human and AI Error Detection</em>. Carnegie Mellon University Human-AI Collaboration Lab.</a> <a href="#fnref:10" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:11">
      <p><a href="https://responsible.ai/publications/complementary-error-detection">Berkeley-Stanford Collaborative. (2025). <em>Complementary Error Detection in Human-AI Systems</em>. Joint Research Initiative on Responsible AI.</a> <a href="#fnref:11" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:12">
      <p><a href="https://www.fhi.ox.ac.uk/publications/reflective-equilibrium-ai-safety">Bostrom, N., &amp; Yudkowsky, E. (2024). <em>Reflective Equilibrium in Artificial Intelligence Safety</em>. Oxford Future of Humanity Institute Technical Reports.</a> <a href="#fnref:12" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div>

  <a class="u-url" href="/2025/07/14/the-limits-of-reflection-where-ai-self-examination-fails/" hidden></a>

  <div class="post-share">
    <h4>Share this post</h4>
    <div class="share-buttons">
      <a href="https://twitter.com/intent/tweet?text=The+Limits+of+Reflection%3A+Where+AI%27s+Self-Examination+Fails&url=https://reflectedintelligence.com%2F2025%2F07%2F14%2Fthe-limits-of-reflection-where-ai-self-examination-fails%2F" target="_blank"
        title="Share on Twitter"><i class="fab fa-twitter"></i></a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://reflectedintelligence.com%2F2025%2F07%2F14%2Fthe-limits-of-reflection-where-ai-self-examination-fails%2F&title=The+Limits+of+Reflection%3A+Where+AI%27s+Self-Examination+Fails"
        target="_blank" title="Share on LinkedIn"><i class="fab fa-linkedin"></i></a>
      <a href="https://www.facebook.com/sharer/sharer.php?u=https://reflectedintelligence.com%2F2025%2F07%2F14%2Fthe-limits-of-reflection-where-ai-self-examination-fails%2F" target="_blank" title="Share on Facebook"><i
          class="fab fa-facebook"></i></a>
      <a href="mailto:?subject=The+Limits+of+Reflection%3A+Where+AI%27s+Self-Examination+Fails&body=Check out this article: https://reflectedintelligence.com%2F2025%2F07%2F14%2Fthe-limits-of-reflection-where-ai-self-examination-fails%2F" title="Share via Email"><i
          class="fas fa-envelope"></i></a>
    </div>
  </div>
</article>

<div class="post-navigation">
  <div class="post-navigation-links">
    
    <a class="prev" href="/2025/07/07/the-human-ai-reflection-loop-co-evolving-intelligence/"><i class="fas fa-arrow-left"></i> The Human-AI Reflection Loop: Co-evolving Intelligence</a>
    
    
    <a class="next" href="/2025/07/21/reflection-across-architectures-how-different-ai-systems-self-examine/">Reflection Across Architectures: How Different AI Systems Self-Examine <i class="fas fa-arrow-right"></i></a>
    
  </div>
</div>

<script>
  // Add class behaviors for dynamic styling
  document.addEventListener('DOMContentLoaded', function () {
    // Convert first blockquote to a pull-quote if it's short enough
    const firstBlockquote = document.querySelector('.post-content blockquote');
    if (firstBlockquote && firstBlockquote.textContent.length < 200) {
      firstBlockquote.classList.add('pull-quote');
    }

    // Add syntax highlighting line numbers
    document.querySelectorAll('pre.highlight').forEach(function (el) {
      el.classList.add('line-numbers');
    });

    // Highlight sentences marked in markdown (==...==) by adding classes
    document.querySelectorAll('.post-content mark').forEach(function (el) {
      el.classList.add('highlight-sentence');
      if (el.textContent.trim().length > 120) {
        el.classList.add('big-highlight');
      }
    });
  });
</script>
    </div>
  </main>

  <footer class="site-footer h-card">
<data class="u-url" href="/"></data>

<div class="wrapper">
<div class="footer-col-wrapper">
<div class="footer-col footer-col-1">
<h2 class="footer-heading">Reflected Intelligence</h2>
<ul class="contact-list">
<li class="p-name">Evan Volgas</li></ul>
</div>

<div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

<div class="footer-col footer-col-3">
<p>Making AI Smarter</p>
</div>
</div>
</div>
</footer>

</body>

</html>